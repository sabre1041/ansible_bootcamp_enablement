= Lab: Ansible Automation Platform on OpenShift

[abstract]
Explore a working installation of Red Hat Ansible Automation Platform on OpenShift Container Platform using the AAP operator. Learn to navigate existing deployments, deploy your own instances, customize configurations, and troubleshoot the AAP operator in OpenShift environments.

== Learning Objectives

After completing this module, you will be able to:

* Navigate and understand AAP operator deployments on OpenShift
* Deploy custom AAP instances using the operator
* Customize AAP configurations and deployments
* Troubleshoot operator-managed AAP installations
* Understand operator lifecycle management

== 1. Introduction: Why AAP on OCP?

The Ansible Automation Platform Operator provides cloud-native, push-button deployment of new Ansible Automation Platform instances in your OpenShift environment. The Ansible Automation Platform Operator includes resource types to deploy and manage instances of automation controller and private automation hub. It also includes automation controller job resources for defining and launching jobs inside your automation controller deployments.

Deploying Ansible Automation Platform instances with a Kubernetes native operator offers several advantages over launching instances from a playbook deployed on Red Hat OpenShift Container Platform, including upgrades and full lifecycle support for your Red Hat Ansible Automation Platform deployments.

More information can be found on the official AAP on OCP documentation here: https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/installing_on_openshift_container_platform/index.

== 2. Lab Setup: Configuring Your Environment

The demo.redhat.com lab environment provisioned for you is a working OpenShift 4.19 environment with the AAP operator pre-installed and deployed.

== 3. Exercise: Viewing the AAP on OCP managed resources

Let's click around the OpenShift UI to see what's already installed and configured by the operator.

=== 3.1: The installed operator and CRDs

* First let's make sure we're using the `aap` project. In the top left select `Project` -> `aap` if it's not already selected.
* Navigate to `Operators` -> `Installed Operators` and we can see `Ansible Automation Platform`` operator listed and installed in the current project.
* Click on the `Ansible Automation Platform` operator.
* This will navigate to the details page of the operator and all the different components the operator can manage.
* In the top tab click on `All Instances`.
* 5 instances will be shown which are each each Custom Resource Definitions (CRDs) managed by the AAP operator:
** `aap` which is an `AnsibleAutomationPlatform` that relates to the Gateway component of AAP.
** `aap-controller` which is an `AnsibleController` that relates to the Automation Controller component of AAP.
** `aap-eda` which is an `EDA` that relates to the Event-Driven Ansible component of AAP.
** `aap-hub` which is an `AutomationHub` that relates to the Automation Hub component of AAP.
** `aap-lightspeed` which is an `AnsibleLightspeed` CRD that relates to the Ansible Lightspeed component of AAP.
+
NOTE: The `AnsibleAutomationPlatform` CRD deploys and manages the other CRDs listed above. This makes it simple to deploy all the components of AAP together. The `AnsibleAutomationPlatform` CRD simply needs to be configured to let the operator know which components of the platform are desired, and how to deploy them, and the operator takes care of the details.

* Click the `aap` instance to navigate to the `Details` page for the `AnsibleAutomationPlatform` CRD.
* On this page you can view some of the important resources managed by the `AnsibleAutomationPlatform` CRD. For instance, secrets, other CRDs, database configurations, etc.
* Next to the `Details` tab click on `YAML`. This will show you the current YAML specification that defines the CRD.
** For example, take a look at the `spec` key in the YAML definition:
+
[source,yaml,role=execute,subs="verbatim,attributes",title="AnsibleAutomationPlatform CRD Spec"]
----
  controller:
    disabled: false
  eda:
    disabled: false
  hub:
    content:
      replicas: 1
    disabled: false
    file_storage_access_mode: ReadWriteMany
    file_storage_size: 100Gi
    file_storage_storage_class: ocs-external-storagecluster-cephfs
    gunicorn_api_workers: 1
    gunicorn_content_workers: 1
    worker:
      replicas: 1
  image_pull_policy: IfNotPresent
  lightspeed:
    disabled: false
  no_log: true
  redis_mode: standalone
  route_tls_termination_mechanism: Edge
----
** This `spec` definition shows us that the `controller`, `eda`, `hub`, and `lightspeed` components are all desired (`disabled: false`) and some customizations made to the `hub` component specifically.

==== 3.2: Resources managed by the CRDs

Each CRD manages its own set of OCP resources that are needed for the component to integrate into the final AAP deployment.

===== 3.2.1: Deployments

Each CRD will create and manage `deployment` resources that in turn manage the pods and other resources listed below in section 3.2.1.

* Navigate to `Workloads` -> `Deployments`. You'll see a list of created deployments, their pod counts, and other information.
* Click on `aap-controller-task`. Under the `Details` tab you can see information about the deployment resource such as its owner (Which CRD manages this deployment), associated containers, associated volumes, etc.
* Feel free to click on the other tabs to view information about the deployment and it's associated metrics, YAML definition, pods, etc.

===== 3.2.2: Pods

Many pods will be up and running that correlate to the containers running the application pieces of AAP. These pods are ultimately owned by the deployments viewed in the previous section.

* Navigate to `Workloads` -> `Pods`. You'll see a long list of deployed pods and their status, restarts, etc.
* Click on `aap-controller-task-<id>`. Under the `Details` tab you can see information related to this pod such as containers, volumes, conditions, etc.
* Next to the `Details` tab, click on the `Logs` tab. Under the `Containers` drop down, make sure that the `aap-controller-task` container is selected. Observe how you can view the application logs related to the `awx.main.tasks` portion of the application. This may be important for troubleshooting while the application is having trouble launching or managing tasks!
* Under the `Containers` drop down, select the `aap-controller-rsyslog` container. Observe how you now see the logs pertaining to the logging of the application pod. If there are any issues with the `awx-rsyslogd` or external logging, you may see them here.
* Next to the `Details` tab, click on the `Terminal` tab. Under the `Containers` drop down, make sure that the `aap-controller-task` container is selected. You now have a direct terminal connection to the running container. Here you can view files, and interact with the running AWX application by running commands such as `awx-manage`. For example run `awx-manage --help`:
+
[source,bash,role=execute,subs="verbatim,attributes",title="Check AWX Manage Commands"]
----
sh-4.4$ awx-manage --help

Type 'awx-manage help <subcommand>' for help on a specific subcommand.

Available subcommands:

[auth]
    changepassword
...
----
+
TIP: You could also get access to the container terminal using the `oc` CLI tool via `oc rsh aap-controller-task-<id> -c aap-controller-task` as well.

Let's do a similar exercise, but this time taking a look at the AAP web pods.

* Navigate to `Workloads` -> `Pods`.
* Click on `aap-controller-web-<id>`
* Next to the `Details` tab, click on the `Logs` tab. Under the `Containers` drop down, make sure that the `aap-controller-web` container is selected. Observe how you can view the application logs related to the AAP web API. This may be important for troubleshooting while the application is receiving web application requests.
* Next to the `Details` tab, click on the `Terminal` tab. Under the `Containers` drop down, make sure that the `aap-controller-web` container is selected. You now have a direct terminal connection to the running container. Just like in the task pod example before, here you can view files, and interact with the running AWX application by running commands such as `awx-manage`.

===== 3.2.3: PersistentVolumeClaims

Some of the deployed components of the AAP operator may require Persistent Volume Claims to store persistent data.

* Navigate to `Storage` -> `PersistentVolumeClaims`. Here you can view any PVCs and their status, associated PVs, capacity, etc.
* Click on `aap-hub-file-storage`. Under the details tab you can see more information about the PVC such as its storageClass, capacity, used capacity, access mode, etc.

===== 3.2.4: ConfigMaps

The AAP operator will create and manage the configmaps that are used by the application components for storing application settings.

Let's view the configmap that stores the nginx configuration used by the Automation Controller.

* Navigate to `Workloads` -> `ConfigMaps`. Here you can view all configmaps and their size, etc.
* Click on `aap-controller-automationcontroller-configmap`. Under `Details` we can see information about the configmap such as its owner and its data.
* Under `Data` take a look at the different objects that belong to this particular configmap.
* Look at the `nginx_conf` object, this is the nginx configuration used for the Automation Controller application.
* Look at the `settings` object, this is the `settings.py` file for the Automation Controller application that is mounted at `/etc/tower/settings.py`.

NOTE: The data for each configmap is handled by the AAP operator, any changes wanted to these configmaps should not be done manually by editing the configmaps, the operator may override any changes applied. If changes to the values of these configmaps are wanted, they should be applied by modifying the correct keys underneath the CRD `spec`.

===== 3.2.5: Secrets

The AAP operator will create and manage sensitive secrets needed by the AAP application. These can range from database configuration details, application login password, database encryption keys, application SSL certificates, and others.

For instance, when the AAP operator does its initial deployment, by default it will create a password for the `admin` user that can be used to login to the AAP platform once it's fully deployed. Let's take a look at it now.

* Navigate to `Workloads` -> `Secrets`. Here you can view any secrets and their type, size, etc.
* Click on `aap-admin-password`. Under `Details` we can see information about the secret and its data.
* Under `Data` click the `Reveal values` button to show the hidden password. Go ahead and copy the password and we'll use it in the next section.

===== 3.2.6: Routes

The AAP operator also handles creating the services needed for the application to route traffic internally among its components, and the routes needed for external access to the web application itself.

Let's look at the routes that are created.

* Navigate to `Networking` -> `Routes`. Here you can view each created route and their status, location, etc.
* Click on `aap`. Under `Details` we can see information about the route and it's service, certificates, wildcard policies, etc. This route happens to belong to the Gateway component of the AAP deployment. This is where all API requests get routed through and also where we can access the UI from.
* Under `Details` and `Location` you can see the externally accessible URL which we can use to access the deployed Ansible Automation Platform instance. Click on the link which should look something like https://aap-aap.apps.cluster-5xd6d.dynamic.redhatworkshops.io.
* A new browser tab should open which will be a login page to AAP. For user type in `admin` and for the password paste the value copied from the `aap-admin-password` secret in the previous `3.2.5` section.

Congratulations you're now logged into the Ansible Automation Platform application deployed and managed by the AAP on OCP operator!

===== 3.2.7: Others

Examples of other OCP resources that are managed by the operator include, but may not be limited to:

* StatefulSets
* Jobs
* ReplicaSets
* HorizontalPodAutoscalers
* Services
* Roles
* RoleBindings
* ServiceAccounts
* etc

==== 3.3: Operator manager pods

Another aspect of the AAP operator is the operator controller manager pods. These pods belong to the Operator Lifecycle Manager of the AAP operator.

The purpose of these pods is to automate the process of installing, updating, and managing operators and their associated operands within a Kubernetes cluster.

These pods are installed when the operator is installed.

There are two ways to install the AAP operator.

1. Cluster scoped installation.

2. Namespace scoped installation.

==== 3.3.1 Cluster scoped installation

With a cluster scoped installation, one set of operator controller manager pods are installed into a specific namespace on the OpenShift cluster.

This set of pods is responsible for managing one or more sets of AAP deployments in separate namespaces.

In essence, this single set of operator controller manager pods watches all the namespaces on the cluster for any of the customer CRDs mentioned in step 3.1 above and for managing their desired state.

The benefit of this approach is a single set of operator controller manager pods can manage many AAP deployments on a single cluster thus less resources consumed by the operator manager controller pods.

The downside is that each deployed instance of AAP on the OpenShift cluster must be on the same exact version.

==== 3.3.2 Namespace scoped installation

With a namespace scoped installation,  one or more sets of operator controller manager pods are installed into specific namespaces on the OpenShift cluster.

Each set of pods is responsible for managing *only* only one AAP deployment in the same namespace into which the operator is installed.

In essence, there can be as many deployments of the operator controller manager pods each watching and managing a single namespace on the cluster.

The benefit of this approach is that each operator controller manager pods can be on separate AAP versions and thus every AAP deployment can be on a separate version and lifecycle.

The down side each set of operator controller manager pods consumes resources and ultimately this approach will consume more total resources when deploying many AAP deployments on a single OCP cluster.

==== 3.3.3 What does this lab use?

The OCP demonstration environment provided in this lab utilizes namespace scoped operator installations. This will allow the student to deploy another working AAP operator onto the same cluster as viewed in the previous section without mixing resources.

== 4. Exercise: Deploy another AAP instance using the AAP Operator

Now that you're familiar with different components that are managed by the AAP operator, let's try to deploy another instance onto the same OCP cluster.

This will demonstrate the steps needed to deploy an instance of the AAP operator and how to make some customizations to the deployment.

==== 4.1: Create a new namespace

First, let's create a new project in which the AAP operator can be installed into.

* Navigate to `Home` -> `Projects`.
* Click on the `Create Project` button.
* Fill out the name field with `my-aap` and hit `Create`.

You are now redirected to the `Project details` page of the newly created project.

==== 4.2: Install the operator

Now that we have a project to work in, let's install another instance of the AAP operator into this namespace.

* Navigate to `Operators` -> `OperatorHub`.
* Underneath `All Items` use the `Filter by keyword...` input and enter `ansible`.
* Click on the `Ansible Automation Platform` box shown.
* A dialog box with information about the operator will be shown. Feel free to read details and information about the operator.
* Underneath `Channel` select `stable-2.5`.
* Click the `Install` button.

Another dialog box will be shown with more options.

* The only change that needs to be made is under `Installed Namespace` select the `Select a Namespace` radio. Ensure the namespace that was created in the previous step is shown in the dropdown: `my-aap`.
* Click the `Install` button.

The operator will take a short moment to install itself into the selected namespace.

* Navigate to `Operators` -> `Installed Operators`.
* Next to `Project:` in the top left ensure `my-aap` is the project shown.

Under the list of installed operators you should now see `Ansible Automation Platform` with a version of `2.5.+0.1...`.

The operator is now successfully installed into the `my-aap` namespace using a namespace scoped installation method.

==== 4.3: Create a custom admin secret

By default the AAP operator will create a secret containing a random value for the initial admin password used to log into the deployed AAP instance.

Let's deviate from that a bit and create our own secret and value that we will tell the operator to use instead.

* Navigate to `Workloads` -> `Secrets`.
* Click on the `Create` button and select `Key/value secret`.
* For `Secret name` enter `my-aap-admin-secret`.
* For `Key` enter `password`, this is the name of the key that the operator will look for in this secret and *must* be named `password`.
* For value enter `supersecret` or any other value you'd like.
* Click the `Create` button.

You are now redirected to the `Secret details` page of the newly created secret. We'll reference the newly created secret in the following section.

==== 4.4: Deploy the operator

Now we'll deploy a new AAP instance using the operator.

* Navigate to `Operators` -> `Installed Operators`.
* Next to `Project:` in the top left ensure `my-aap` is the project shown.
* Click on the `Ansible Automation Platform` operator.
* In the toolbar click on `All instances`.
* Click on the `Create new` button and select `Ansible Automation Platform`.

This will bring up the form view to customize the values of the Ansible Automation Platform deployment.

For this exercise we'll use the YAML view and paste a simple snippet in.

* Click on the `YAML view` radio button.
* In the code entry field paste the following YAML in:
+
[source,yaml,role=execute,subs="verbatim,attributes",title="Custom AAP Deployment"]
----
apiVersion: aap.ansible.com/v1alpha1
kind: AnsibleAutomationPlatform
metadata:
  name: aap
  namespace: my-aap
spec:
  admin_password_secret: my-aap-admin-secret
  image_pull_policy: IfNotPresent
  no_log: false
  redis_mode: standalone
  route_tls_termination_mechanism: Edge
  controller:
    disabled: false
  eda:
    disabled: true
  hub:
    disabled: true
  lightspeed:
    disabled: true
----
* Click the `Create` button.

The snippet above is a YAML definition of the `AnsibleAutomationPlatform` we want the operator to deploy. It is asking for the Gateway and Automation Controller components to be created, but disabling deployment of Automation Hub, EDA, and Lightspeed for now.

NOTE: Notice the value of `namespace: my-aap` in the snippet above is the name of our created project from earlier steps. As well, notice the value of `admin_password_secret: my-aap-admin-secret` is the name of the secret created earlier.

The operator will now recognize the newly created `AnsibleAutomationPlatform` CRD and begin creating and managing the components until the platform is fully deployed.

In the next section we'll take a look at different ways to monitor the progress of the actions the operator is performing.

==== 4.5: Monitor the installation progress

There are several ways to monitor what actions the operator is taking:

* You can track the logs of the operator manager pods for each component by looking at the `<component>-controller-operator-manager-<id>` pod logs.
* You'll start noticing deployments, pods, secrets, etc start to be created and changing. Feel free to monitor their individual progress like in sections 3.2.
* Resources belonging to the CRD start to get populated under the `Details` -> `Resources` page of it.

When the `AnsibleAutomationPlatform` CRD is successfully deployed, the status of it and the `AutomationController` instance should show `Conditions: Running, Successful`.

This can be checked by:

* Navigate to `Operators` -> `Installed Operators`.
* Next to `Project:` in the top left ensure `my-aap` is the project shown.
* Click on the `Ansible Automation Platform` operator.
* In the toolbar click on `All instances`.
* Look at what is displayed in the `Status` column on this page.
* When the status for both components shows `Conditions: Running, Successful` then proceed to the next section.
+
NOTE: It will take about 10 minutes for the AAP deployment to complete.

==== 4.6: Access the deployed instance

Now that the operator is showing the AAP instance as successfully deployed, let's try to access it.

* Click on `Networking` -> `Routes`.
* Click on the `Location` URL for the `aap` route.

A new browser tab will be opened to the URL and you should see a login page for Ansible Automation Platform.

* For the credentials enter username: `admin` and password: `supersecret`.

You're now logged into the newly deployed AAP instance!

Go ahead and attach a subscription to this deployment by using a service account and password and choosing any valid subscription. Your Red Hat login used for cloud.redhat.com should have many subscriptions to choose from.

Once this is down you will see the AAP dashboard.

Note that the only component of AAP that is currently deployed is Automation Controller.

== 5. Exercise: Modify the existing deployment

The operator will manage the desired state of the created CRDs.

For instance, if changes are manually made to operator managed resources like deployments, configmaps, etc, then the operator may override those changes and reapply the desired state according the the deployed `AnsibleAutomationPlatform`, `AutomationController`, etc CRDs.

Likewise, if updates are made to already deployed `AnsibleAutomationPlatform`, `AutomationController`, etc CRDs than the operator will reconcile already deployed instances and apply the desired configuration automatically.

Let's demonstrate this by modifying the already created `AnsibleAutomationPlatform` CRD to also deploy an Automation hub instance and observe how the AAP deployment gets updated.

* Navigate to `Operators` -> `Installed Operators`.
* Next to `Project:` in the top left ensure `my-aap` is the project shown.
* Click on the `Ansible Automation Platform` operator.
* In the toolbar click on `All instances`.
* Click on the `aap` named resource.
* Click on the `YAML` toolbar button.
* In the code entry field update the `spec` key to the following:
+
[source,yaml,role=execute,subs="verbatim,attributes",title="Custom AAP Deployment"]
----
...
spec:
  admin_password_secret: my-aap-admin-secret
  image_pull_policy: IfNotPresent
  no_log: false
  redis_mode: standalone
  route_tls_termination_mechanism: Edge
  controller:
    disabled: false
  eda:
    disabled: true
  hub:
    disabled: false
    content:
      replicas: 1
    file_storage_access_mode: ReadWriteMany
    file_storage_size: 100Gi
    file_storage_storage_class: ocs-external-storagecluster-cephfs
    gunicorn_api_workers: 1
    gunicorn_content_workers: 1
    worker:
      replicas: 1
  lightspeed:
    disabled: true
...
----
* Click the `Save` button.
+
NOTE: Note the only changes made from originally deployed spec in section 4.4 is the change of child keys of the `hub` parent key.

Just like in section 4.5, the different components of the operator can be observed to monitor the changes being made.

NOTE: The status of the `AnsibleAutomationPlatform` CRD will change to `Status: Running` while Automation Hub is deploying.

When the status of the `AutomationHub` shows `Conditions: Database-Ready, Automationhub-API-Ready, Automationhub-Operator-Finished-Execution, Automationhub-Web-Ready, Automationhub-Content-Ready, Automationhub-Worker-Ready, Automationhub-Routes-Ready`, the Automation Hub component of AAP should be successfully deployed.

NOTE: Automation Hub will take about 10 minutes to successfully deploy.

Just like in section 4.6 before, log into the AAP instance again and see that the Automation Hub component of AAP is now deployed.

== 6. Exercise: Modify the default AAP container group

The operator deployed AAP instance is pre-configured with a default container group. A container group is an instance group that points to an OCP cluster. In this case, the OCP cluster that the operator was installed on.

By default, the container group is setup to deploy job pods in the same namespace that the `AnsibleAutomationPlatform` CRD was created in.

AAP allows you to edit the default container group, or create new ones, and modify the k8s request that AAP makes on each job execution.

More detailed information on container groups can be found here: https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.6/html-single/using_automation_execution/index#controller-container-groups.

Before we modify the container group, let's make a slight configuration change to the AAP deployment that will allow job containers to persist after running, so the can be observed.

* Log into the deployed AAP instance.
* Navigate to `Settings` -> `Automation Execution` -> `Troubleshooting`.
* Click on the `Edit` button.
* Uncheck the `Release Receptor Work` checkbox.
* Click the `Save` button.

Now, let's walk through making a slight change to the default container group on the deployed AAP instance.

* Navigate to `Automation Execution` -> `Infrastructure` -> `Instance Groups`.
* Click on the `default` container group.
* Click the `Edit container group` button.
* Check the `Customize pod spec` option.

You'll see a `Pod spec override` text box appear with a lengthy YAML snippet. This represents spec for the k8s API request that is made by AAP each time a job pod is launched.

Let's modify the spec slightly to add a custom label to each job pod.

Edit the `metadata` key to look like such:

[source,yaml,role=execute,subs="verbatim,attributes",title="Custom AAP Deployment"]
----
...
metadata:
  namespace: my-aap
  labels:
    ansible_job: ''
    my_label: foobar
...
----

* Click the `Save container group` button.

Now let's run a demo job and observe the job pod that gets launched.

* Navigate to `Automation Execution` -> `Templates`.
* Click on `Demo Job Template`.
* Click the `Launch template` button.
* Wait for the job to successfully complete.

NOTE: The job template was successfully ran which means that an OCP pod was launched and the ansible playbook was successfully executed within it. Normally this pod would be terminated and removed upon success by AAP. But because we unchecked the `Release Receptor Work` option previously, this pod will not be removed and it will still be available for inspection if needed.

Let's observe the created job pod in the OCP UI.

* Navigate back to the OCP console.
* Navigate to `Workloads` -> `Pods`.
* In the filter text box enter `automation-job`.
* Click on the `automation-job-<id>-<guid>` pod.
* Observe the labels attached to this pod under `Labels`.

You will see the pod has an additional label `my_label=foobar`. This is because of the change we did to the container group YAML spec above.

This is a very simple example of modifying the container group specification to customize the k8s pod API request. More advanced examples of customizations a user may make for real-world deployments may be:

* Launch job pods in a separate namespace from the core AAP platform pods.
* Modify the resource requests and limits of job pods.
* Attach volume mounts to each job pod request.
* Edit the affinity or anti-affinity of job pods to certain OCP nodes.

This demonstrates how easy and flexible container groups can be used and adjusted to manage AAP automation workloads.

== Conclusion

You have successfully explored Ansible Automation Platform deployment and management on OpenShift:

. Examined the resources managed by the AAP operator including deployments, pods, secrets, and routes
. Learned about cluster-scoped vs namespace-scoped operator installations
. Deployed a custom AAP instance with specific configurations
. Monitored deployment progress and accessed the running platform
. Understood the various CRDs and their purposes in the AAP ecosystem

This knowledge prepares you to deploy, manage, and troubleshoot AAP on OpenShift in enterprise environments, leveraging the power of Kubernetes-native automation platform management.

== Helpful Links

For additional reference and deeper learning on AAP on OpenShift:

. https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/deploying_the_red_hat_ansible_automation_platform_operator_on_openshift/index[AAP Operator Deployment Guide]
. https://docs.openshift.com/container-platform/latest/operators/understanding/olm/olm-understanding-olm.html[OpenShift Operator Lifecycle Manager]
. https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/red_hat_ansible_automation_platform_installation_guide/index[Ansible Automation Platform Installation Guide]
. https://kubernetes.io/docs/concepts/extend-kubernetes/operator/[Kubernetes Operators]
