= Lab: Advanced Collection Testing with a `db_server` Role

'''

== 1. Introduction: Test-Driven Development with Molecule

Test-Driven Development (TDD) is a software development approach where tests are written before the code they validate. In Ansible automation, Molecule enables this practice by providing a framework for testing roles in isolated environments.

Why use Molecule for Ansible roles?

* *Isolated Testing*: Tests run in clean, ephemeral containers ensuring consistent results.
* *Idempotence Verification*: Confirms roles can run multiple times without side effects.
* *Functional Testing*: Validates that roles actually work as intended, not just that they run.
* *CI/CD Integration*: Enables automated testing in pipelines before deployment.

=== 1.1 Objective

You will write and test an Ansible role that **manages** a PostgreSQL database running inside a pre-built container. Instead of installing the database software, your role will be responsible for creating users and databases within the running service.

This lab demonstrates a modern, container-native testing workflow where the Molecule `default` scenario provisions the database container using environment variables, and a separate `db_server` scenario runs a role to configure it.

'''

== Step 2: Create and Prepare the Collection

First, generate the collection and add the `db_server` role resource.

. Create the collection skeleton:

[source,bash,role=execute,subs="verbatim,attributes"]
----
ansible-creator init collection ansible_bootcamp.my_collection
cd ansible_bootcamp.my_collection
----

. Add the `db_server` role:

[source,bash,role=execute,subs="verbatim,attributes"]
----
ansible-creator add resource role db_server .
----

'''

== Step 3: Develop the `db_server` Role

The role's responsibility is now much simpler. It assumes PostgreSQL is already running and only needs to create our application's user and database.

Modify the files inside `roles/db_server/` to install and configure PostgreSQL.

[source,yaml,role=execute,subs="verbatim,attributes",title="roles/db_server/defaults/main.yml"]
----
---
# defaults file for ansible_bootcamp.my_collection.db_server
db_server_db_name: "webapp_prod"
db_server_db_user: "webapp_user"
db_server_db_password: "SecurePassword123"
...

----

Replace the entire contents of this file. Notice there are no installation, initialization, or service management tasks.

[source,yaml,role=execute,subs="verbatim,attributes",title="roles/db_server/tasks/main.yml"]
----
---
# tasks file for ansible_bootcamp.my_collection.db_server
- name: Create the application database
  community.postgresql.postgresql_db:
    name: "{{ db_server_db_name }}"
    state: present

- name: Create the application database user
  community.postgresql.postgresql_user:
    login_db: "{{ db_server_db_name }}"
    name: "{{ db_server_db_user }}"
    password: "{{ db_server_db_password }}"
    state: present

- name: Grant CONNECT on database to our user
  community.postgresql.postgresql_privs:
    login_db: "{{ db_server_db_name }}"
    privs: CONNECT
    type: database
    obj: "{{ db_server_db_name }}"
    roles: "{{ db_server_db_user }}"

- name: Grant USAGE and CREATE on schema public to our user
  community.postgresql.postgresql_privs:
    login_db: "{{ db_server_db_name }}"
    privs: ALL
    type: schema
    obj: public
    roles: "{{ db_server_db_user }}"

...

----

'''

== Step 3.5: Add Argument Specification for Role Validation

The `argument_spec` file provides a way to validate role arguments, document their purpose, and define default values. This file is placed in `roles/db_server/meta/argument_specs.yml` and helps ensure that the role receives the correct parameters.

=== Why Use argument_spec?

* *Input Validation*: Ensures required parameters are provided and have correct types
* *Documentation*: Self-documenting roles that IDEs and documentation tools can use
* *Error Prevention*: Catches configuration errors early in the execution
* *Better UX*: Provides clear error messages when parameters are missing or invalid

=== Create the argument_specs.yml File

Create the meta directory and argument specification file:

[source,yaml,role=execute,subs="verbatim,attributes",title="roles/db_server/meta/argument_specs.yml"]
----
---
# argument spec file for ansible_bootcamp.my_collection.db_server
argument_specs:
  main:
    short_description: "Arguments for the db_server role"
    description: "This role manages PostgreSQL database users and databases within an existing PostgreSQL instance."
    author: "Ansible Bootcamp"
    options:
      db_server_db_name:
        type: "str"
        required: true
        description: "The name of the database to create"
        default: "webapp_prod"

      db_server_db_user:
        type: "str"
        required: true
        description: "The name of the database user to create"
        default: "webapp_user"

      db_server_db_password:
        type: "str"
        required: true
        description: "The password for the database user"
        default: "SecurePassword123"
        no_log: true
----

This argument specification:

* Defines three main options corresponding to your role's variables
* Marks all parameters as required (even though they have defaults)
* Uses `type: "str"` for string validation
* Includes descriptions for documentation
* Uses `no_log: true` for the password to prevent it from appearing in logs

'''

== Step 4: Create the PostgreSQL Container Image

Before running the tests, you need to create a custom PostgreSQL container image that includes the necessary Python PostgreSQL libraries for the Ansible modules to work.

=== Create the Dockerfile

Create a `Dockerfile` in the root of your collection:

[source,text,role=execute,subs="verbatim,attributes",title="Dockerfile"]
----
FROM registry.redhat.io/rhel9/postgresql-16:latest
USER root
RUN dnf install -y python3-psycopg2
USER postgres
----

=== Build the Container Image

Build the custom PostgreSQL container image:

[source,bash,role=execute,subs="verbatim,attributes"]
----
podman build -t localhost/my_psql .
----

'''

== Step 5: Configure the Advanced Molecule Scenarios

You will now create and configure your scenarios in a `molecule/` directory at the root of the collection.

=== Create and Configure the `db_server` (Component Testing) Scenario
This scenario performs the actual test of the role.

**Initialize the new scenario:**

[source,bash,role=execute,subs="verbatim,attributes"]
----
molecule init scenario db_server
----

**Move the scenario to the extensions directory:**

[source,bash,role=execute,subs="verbatim,attributes"]
----
mv molecule/db_server extensions/molecule/; rmdir molecule
----

**Move some playbooks into utils directory:**

[source,bash,role=execute,subs="verbatim,attributes"]
----
mv extensions/molecule/db_server/{converge.yml,create.yml,destroy.yml} extensions/molecule/utils/playbooks/
----

**Delete unused example directory:**

[source,bash,role=execute,subs="verbatim,attributes"]
----
rm -rf extensions/molecule/integration_hello_world
----

**Modify `extensions/molecule/db_server/molecule.yml`:**
   Replace the contents of this file with the following configuration:

[source,yaml,role=execute,subs="verbatim,attributes",title="extensions/molecule/db_server/molecule.yml"]
----
---
dependency:
  name: galaxy
  options:
    requirements-file: ${MOLECULE_SCENARIO_DIRECTORY}/requirements.yml
driver:
  name: podman
platforms:
  - name: instance
    image: localhost/my_psql
    container_command: run-postgresql
    entrypoint: container-entrypoint
    ports:
      - 5432:5432
    env:
      POSTGRESQL_ADMIN_PASSWORD: AdminSecurePassword123
    pre_build_image: true
    cgroupns_mode: host
    tmpfs:
      "/run": "rw,mode=1777"
      "/tmp": "rw,mode=1777"
    volumes:
      - /sys/fs/cgroup:/sys/fs/cgroup:rw
provisioner:
  name: ansible
  playbooks:
    cleanup: ../utils/playbooks/cleanup.yml
    converge: ../utils/playbooks/converge.yml
    destroy: ../utils/playbooks/destroy.yml
    prepare: ../utils/playbooks/prepare.yml
    create: ../utils/playbooks/create.yml
    verify: ../utils/playbooks/verify.yml
  inventory:
    group_vars:
      all:
        ansible_connection: containers.podman.podman
        db_server_db_name: "webapp_prod"
        db_server_db_user: "webapp_user"
        db_server_db_password: "SecurePassword123"
verifier:
  name: ansible
...

----

[source,yaml,role=execute,subs="verbatim,attributes",title="extensions/molecule/db_server/requirements.yml"]
----
---
collections:
  - containers.podman
  - community.postgresql
...

----

The scenario uses shared playbook files for container management and testing. Create the following files:

[source,yaml,role=execute,subs="verbatim,attributes",title="extensions/molecule/db_server/converge.yml"]
----
---
- name: Converge
  hosts: all
  tasks:
    - name: "Wait for PostgreSQL to be ready"
      ansible.builtin.wait_for:
        host: "{{ ansible_host }}"
        port: 5432
        delay: 5   # Time to wait before first check
        timeout: 60 # Total time to wait before failing
      delegate_to: localhost

    - name: "Wait for PostgreSQL to accept connections inside container"
      ansible.builtin.command: psql -h localhost -U {{ db_server_db_user }} -d {{ db_server_db_name }} -c "SELECT 1;"
      register: postgres_check
      until: postgres_check.rc == 0
      retries: 30
      delay: 2
      ignore_errors: true
      changed_when: false

    - name: "Include the db_server role"
      ansible.builtin.include_role:
        name: "ansible_bootcamp.my_collection.db_server"
...

----

The `verify.yml` playbook performs functional testing to validate that your role not only ran successfully, but actually achieved the desired results. This phase includes tests that check database connectivity, verify data persistence, and confirm your automation works end-to-end.

[source,yaml,role=execute,subs="verbatim,attributes",title="extensions/molecule/db_server/verify.yml"]
----
---
- name: Verify
  hosts: all
  vars:
    db_server_db_name: "webapp_prod"
    db_server_db_user: "webapp_user"
    db_server_db_password: "SecurePassword123"
  tasks:
    - name: "FUNCTIONAL TEST: Connect as the new user and create a table"
      community.postgresql.postgresql_query:
        login_user: "{{ db_server_db_user }}"
        login_password: "{{ db_server_db_password }}"
        db: "{{ db_server_db_name }}"
        query: "CREATE TABLE IF NOT EXISTS molecule_verify (id INT);"

    - name: "FUNCTIONAL TEST: Write data to the new table"
      community.postgresql.postgresql_query:
        login_user: "{{ db_server_db_user }}"
        login_password: "{{ db_server_db_password }}"
        db: "{{ db_server_db_name }}"
        query: "INSERT INTO molecule_verify (id) VALUES (1);"

    - name: "FUNCTIONAL TEST: Read data back and verify the result"
      community.postgresql.postgresql_query:
        login_user: "{{ db_server_db_user }}"
        login_password: "{{ db_server_db_password }}"
        db: "{{ db_server_db_name }}"
        query: "SELECT COUNT(*) FROM molecule_verify;"
      register: query_result
      changed_when: false

    - name: "Assert that one record was found"
      ansible.builtin.assert:
        that:
          - query_result.query_result[0].count == 1
        fail_msg: "Verification failed! Expected to find 1 record but found {{ query_result.query_result[0].count }}."
        success_msg: "Verification successful! The DB user can connect, write, and read."
...

----

The `cleanup.yml` playbook handles cleanup of temporary files and artifacts created during testing, helping maintain a clean test environment between test runs without destroying the actual test infrastructure.

[source,yaml,role=execute,subs="verbatim,attributes",title="extensions/molecule/utils/playbooks/cleanup.yml"]
----
---
- name: Cleanup container instances
  hosts: molecule
  gather_facts: false
  tasks:
    - name: Check if container is running
      containers.podman.podman_container_info:
        name: "{{ groups['all'] }}"
      register: container_info
      delegate_to: localhost

    - name: Remove temporary files from running containers
      ansible.builtin.file:
        path: /tmp/molecule_os_info.txt
        state: absent
      when:
        - container_info.containers | length > 0
        - container_info.containers[0].State.Running
      failed_when: false
...

----

The `destroy.yml` playbook tears down the test infrastructure completely. This final phase in Molecule's lifecycle ensures that containers, virtual machines, and other test resources are properly cleaned up after testing is complete.

[source,yaml,role=execute,subs="verbatim,attributes",title="extensions/molecule/utils/playbooks/destroy.yml"]
----
---
- name: Destroy container instances
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Get info for all containers
      containers.podman.podman_container_info:
        name: "{{ item['name'] }}"
      loop: "{{ molecule_yml.platforms }}"
      register: podman_infos

    - name: Kill container if running
      containers.podman.podman_container:
        name: "{{ item.item['name'] }}"
        state: stopped
        timeout: 2
      loop: "{{ podman_infos.results }}"
      loop_control:
        label: "{{ item.item }}"
      when:
        - item.containers | length > 0
        - item.containers[0].State.Status == "running"

    - name: Remove container to ensure clean state
      containers.podman.podman_container:
        name: "{{ item.item['name'] }}"
        state: absent
      loop: "{{ podman_infos.results }}"
      loop_control:
        label: "{{ item.item }}"
      when: item.containers | length > 0
...

----

The `noop.yml` playbook is a placeholder that performs no operations. It can be used as a template or when you need a playbook that does nothing during specific testing phases.

[source,yaml,role=execute,subs="verbatim,attributes",title="extensions/molecule/utils/playbooks/noop.yml"]
----
---
- name: No-op
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Run a noop
      ansible.builtin.debug:
        msg: "This does nothing!"
...
----

'''

=== Additional Molecule Playbooks

Molecule supports several other standard playbooks that we haven't implemented in this lab:

* *`idempotence.yml`*: Tests that running your role multiple times produces the same result without unwanted side effects. This verifies that your automation is truly idempotent.

* *`side_effect.yml`*: Tests the impact of your role on other parts of the system or external dependencies. Useful for testing integration effects or cross-system interactions.

These additional playbooks can be configured in your `molecule.yml` file under the `provisioner.playbooks` section when you need more advanced testing scenarios.

'''

== Step 6: Build and Install the Collection

Before running the molecule tests, you need to build and install the collection so that the role can be found by Ansible.

Update the `galaxy.yml` file to add a dependency on `"community.postgresql": "*"` and increment the version number.

[source,bash,role=execute,subs="verbatim,attributes"]
----
ansible-galaxy collection build .
ansible-galaxy collection install ansible_bootcamp-my_collection-*.tar.gz --force
ansible-galaxy collection publish -s {aap_controller_web_url}/api/galaxy/ ansible_bootcamp-my_collection-*.tar.gz --token YOUR_API_TOKEN_HERE
----

'''

== Step 6.2: Understanding the Test Sequence

Molecule executes a comprehensive test sequence to validate your role:

*Dependency*: Install required Ansible collections (community.postgresql)

*Create*: Start an isolated Podman container with UBI9 base image

*Prepare*: (Optional preparation steps - skipped in this scenario)

*Converge*: Execute the db_server role to install and configure PostgreSQL

*Idempotence*: Run the role again to verify no changes occur (ensures safe re-runs)

*Verify*: Execute functional tests to validate database operations work correctly

*Destroy*: Clean up the test container

The test suite validates that your db_server role successfully installs PostgreSQL, creates the application database and user, and enables functional database operations.

Further documentation are provided below for those who are interested to learn more:

* https://molecule.readthedocs.io/[Molecule Documentation]
* https://ansible.readthedocs.io/projects/creator/[Ansible Creator Documentation]
* https://docs.ansible.com/ansible/latest/collections_guide/index.html[Ansible Collections Guide]

== Step 7: Run the Full Test Suite!

Change to the extensions directory and execute the test suite.

[source,bash,role=execute]
----
cd extensions
molecule test --all
----

This corrected structure removes the invalid `extends` keyword and uses a more explicit configuration for each scenario, which will resolve the validation error.

== Conclusion

Congratulations! You have successfully implemented Test-Driven Development for Ansible automation by:

* Creating an Ansible collection with a db_server role
* Implementing PostgreSQL installation and configuration
* Configuring Molecule for isolated testing with functional verification
* Running comprehensive tests that validate role functionality and idempotence

This TDD approach ensures your automation is reliable, maintainable, and ready for production deployment. The skills you've learned here form the foundation for developing high-quality Ansible content that can be confidently deployed in enterprise environments.
